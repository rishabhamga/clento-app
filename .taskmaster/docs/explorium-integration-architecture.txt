AI SDR Platform Architecture (Next.js + Explorium MCP)
1. Natural Language ICP Input Processing
User Input Format: Allow B2B users to describe their Ideal Customer Profile in a single, clear natural-language sentence. For example: “I want to target mid-size B2B SaaS companies in the US with 50–500 employees where the CTO or Head of Engineering is the decision maker.” This format explicitly mentions: target company type/industry (“B2B SaaS companies”), geography (“US”), company size (“50–500 employees”), and key decision-maker roles (“CTO or Head of Engineering”). Providing a template or example helps users include all relevant attributes of their ICP in one prompt. Prompt Engineering: On form submission, the system uses an LLM (e.g. OpenAI GPT) to parse the natural-language ICP into structured search parameters. The prompt to the LLM should define the expected output schema (e.g. JSON with fields like industry, company_size, location, job_roles, etc.) and include instructions/rules for format. For instance, instruct the model to use standardized codes or terms – “Output country as ISO 2-letter code (e.g. ‘US’), company size as predefined ranges (‘11-50’, ‘51-200’, etc.), and match job roles to known titles or seniority levels.” This “context engineering” ensures the LLM’s output aligns with Explorium’s API requirements (for example, using "country_code": "us" instead of "country": "United States"). Providing a few examples in the prompt (few-shot learning) can demonstrate how to map phrases like “mid-size” or “SaaS” to structured filters (e.g. company_size: ["51-200","201-500"], linkedin_category: ["software development"] for SaaS software industry
developers.explorium.ai
). The Explorium platform supports natural language queries natively, so this approach aligns with best practices for GTM agent design
explorium.ai
. Contextual Data for Parsing: Optionally, incorporate context from onboarding to improve parsing accuracy. For example, if during onboarding the user provided their own company website, the system could fetch their company’s industry via Explorium and inform the LLM (e.g. “The user’s company is a SaaS HR software provider”) so the LLM can infer that the ICP likely involves similar buyer personas. This additional context can guide prompt responses, but it’s important to explicitly tell the LLM how to use it (e.g. “Given the user’s company industry and the ICP description, output filters...”). Conversion to Filters: After obtaining the LLM’s draft filters, the system should validate and refine them. This includes:
Autocompletion for categories – For fields like industry or job title that require specific values, call Explorium’s Autocomplete API before finalizing filters. For example, if the LLM outputs linkedin_category: "SaaS", use the Autocomplete Businesses endpoint to find the closest valid category (likely “Software Development”)
developers.explorium.ai
. Similarly, for job titles or departments, use Autocomplete Prospects to get standardized values if available. This ensures the filters will be accepted by Explorium MCP (which requires using valid category values obtained via autocomplete)
developers.explorium.ai
developers.explorium.ai
.
Synonym and range handling – Map colloquial terms to filter values. For instance, “mid-size” might be interpreted as employee count 51–500 (covering two Explorium size buckets: “51-200” and “201-500”)
developers.explorium.ai
, and roles like “Head of Engineering” should translate to appropriate seniority and department filters (e.g. job_department: ["engineering"] and job_level: ["director","vp"] to capture engineering leaders). The prompt or a post-processing rule can handle this mapping (possibly by maintaining an internal dictionary of common synonyms to filter values).
By combining prompt-based parsing with programmatic validation, the platform converts a free-text ICP into a structured filter object ready for search. This structured ICP is then stored and used in subsequent steps.
2. User Journey and Flow
The platform guides the user through a multi-step journey from onboarding to viewing a tailored prospect list. Below is the step-by-step flow, with details on UI and backend actions: Step 1: Onboarding – Company Profile Input
User Action: Upon signup, the user is prompted to enter their own company’s website or domain.
System Action: The system uses this domain to fetch the user’s company info via Explorium. For example, it can call Match Business and then Enrich Firmographics to identify the company’s industry, size, and location
glama.ai
glama.ai
. This data helps personalize the experience (e.g. pre-selecting relevant industry filters or providing example ICPs in the same field). If Explorium returns that the user’s company is, say, in the “Software” industry with ~200 employees, the UI might suggest an example ICP targeting similar companies (or complementary industries) to kickstart the process. The onboarding step thus grounds the platform with context about who is using it.
Step 2: Define ICP via NLP
User Action: The user accesses an “Define Your Ideal Customer Profile” screen with a natural-language input box (pre-filled with a hint or the example format). The user types their ICP description in plain language (e.g. the SaaS targeting example above).
System Action: When the user submits the ICP description, the backend invokes the LLM NLP processing pipeline. The LLM (with engineered prompt as described in section 1) parses the description into structured filters. The system then calls Explorium’s Autocomplete endpoints to validate any category or title filters and attaches the corresponding filter codes/values
developers.explorium.ai
developers.explorium.ai
. For instance, if the user wrote “SaaS companies in the US,” the system ensures the filter includes "country_code": "us" and a valid industry classification for “SaaS” (likely the LinkedIn category “software development”
developers.explorium.ai
). The output might be a JSON like:
{
  "country_code": ["us"],
  "company_size": ["51-200","201-500"],
  "linkedin_category": ["software development"],
  "job_title": ["CTO","Head of Engineering"]
}
This structured ICP filter object is saved (e.g. in a database or in-memory state) and will be used for actual searching. Step 3: Search Preview & ICP Confirmation
User Action: The UI now presents a preview of the interpreted ICP and potential search results for confirmation. This preview includes two parts: (a) a filter summary showing how the system interpreted the ICP (e.g. Industry: Software; Location: US; Company Size: 51–500; Roles: CTO or Head of Engineering), and (b) an optional sample of target companies or a count of matches. For example, the platform might display: “Approximately 1,200 companies match your criteria. Examples include TechVision Inc (120 employees, uses AWS) and DataFlow Systems (86 employees) in New York.”
developers.explorium.ai
developers.explorium.ai
. These examples can be obtained by performing a quick Explorium fetch with a small page size to grab a few representative companies. Explorium’s fetch_businesses can return company names and attributes to populate this preview
developers.explorium.ai
. This step lets users verify the ICP filters are on target before pulling a full list.
System Action: To generate the preview, the system calls Explorium’s Business Statistics or a limited Fetch Businesses query. The Business Statistics endpoint can provide aggregate counts (e.g. number of companies in the US SaaS category of that size) for a high-level gauge
developers.explorium.ai
developers.explorium.ai
. Alternatively, a small fetch_businesses (with page_size of say 5) can retrieve a few sample companies
developers.explorium.ai
. The system uses the previously constructed filter object for these calls. The results are displayed in the UI for user review. This is also the stage to allow filter fine-tuning – the user can adjust any filter via UI controls (e.g. sliders for employee range, checkboxes for additional industries, etc.) if the preview doesn’t look right. Such adjustments update the filter object.
Step 4: Save ICP Filters
User Action: Satisfied with the ICP definition, the user saves it (e.g. naming this profile “Mid-size US SaaS Targets”).
System Action: The platform persists the ICP profile to a database. This includes storing the structured filters (likely as a JSON blob or in a structured table) along with meta-data like profile name, creation date, user ID, etc. By saving the exact filter parameters, GTM engineers and sales teams can reuse this ICP in the future without re-entering it. For instance, the saved ICP can be loaded later to run a fresh search or to feed into other tools (like campaign workflows). Storing these parameters ensures consistency in targeting across the team. The filters can also be exported or exposed via an API for integration with other systems. (For example, the JSON could be handed off to a marketing automation tool to continuously update a lead list.)
Step 5: Final Search & Prospect List Generation
User Action: The user triggers the final search (e.g. by clicking “Generate Prospect List”). The UI then shows a loading indicator and eventually displays the resulting list of companies or contacts that match the ICP.
System Action: This step is where Explorium’s MCP (Model Context Protocol) data sources are fully leveraged to fetch and enrich prospects. The platform has two possible approaches here (explained in detail in section 3, Filter Strategy): (a) Two-Stage Search (Companies -> Contacts): The system first queries Explorium for companies that fit the ICP, then finds relevant contacts at those companies. In practice, the backend would call POST /v1/businesses with the filters (possibly with mode: "full" to get detailed company info) to retrieve a list of business IDs and basic firmographics
developers.explorium.ai
developers.explorium.ai
. Next, using those business IDs, it calls POST /v1/prospects with person-level filters (e.g. job titles/levels) plus a filter business_id: [<IDs>] to fetch employees at those target companies
developers.explorium.ai
developers.explorium.ai
. This returns a list of prospect IDs (and possibly names, titles, etc.). Finally, for each prospect ID, the system calls POST /v1/prospects/enrich/contact-details to get contact information (verified email addresses, phone numbers, etc.)
developers.explorium.ai
developers.explorium.ai
. The end result is a list of prospects with their company, title, email/phone, and any other chosen fields, which the UI then displays in a table or CRM-like list. (b) One-Stage Search (Direct Contacts): Alternatively, the system can query contacts in one step by calling fetch_prospects with the combined filters (both company attributes and person attributes) in a single API call. Explorium’s prospect search supports filters like company size, industry, location and job role criteria together
developers.explorium.ai
developers.explorium.ai
. For example, a single request can ask for “prospects with job_level = CXO or VP in Finance department, at companies in US-NY in Investment Banking with 1001-5000 employees”, and Explorium will return matching people directly
developers.explorium.ai
. This yields prospect IDs and some profile info. The system would then call the Contact Details enrichment for those IDs to get emails/phones. While this one-stage approach is efficient, the two-stage approach offers more control (e.g. the ability to review the company list first) and aligns with Explorium’s recommended workflow of fetching business IDs then prospect IDs
developers.explorium.ai
developers.explorium.ai
.
UI Display: The Prospect List page might first show the company list (especially if using the two-stage approach) – e.g. 100 target companies with key firmographics – and allow the user to drill down into each to see contacts. Or it can directly display a unified list of contacts with their company column. At this stage, Explorium MCP has been “triggered” to provide both the targeting (who to contact) and data enrichment for outreach. The user can click on a contact to view detailed info (potentially using other enrichments like social media profile or work history if needed
glama.ai
glama.ai
). The platform should also indicate data freshness or any relevant signals (for example, a contact who “changed role recently” could be highlighted if Explorium’s events data shows that
glama.ai
).
Throughout this journey, Explorium MCP integration is seamless to the user – they experience a natural chat-like or form-based interaction while behind the scenes the system translates their intent into data queries and results. Each step that calls Explorium (onboarding enrichment, preview, final fetch, enrichment) happens via server-side API calls to keep the API key secure and to aggregate results before sending to the front-end.
3. Filter Strategy and Data Flow
Company-First vs. Contact-First Search: We recommend a company-first filtering strategy followed by contact filtering. This means identifying a set of target companies that match the ICP, then finding the right people within those organizations. This approach ensures that prospects truly fit both the company criteria and the buyer persona criteria. It also mirrors Explorium’s best practices: many enrichment tools require first obtaining a business_id for each company and a prospect_id for each person
developers.explorium.ai
developers.explorium.ai
. By fetching companies first, the platform can present those companies for review or further filtering (e.g. “remove Company X from the list”) before pulling contacts. It also allows reuse of the company list for different roles if needed (e.g. one ICP could be used to get CTOs and another to get Heads of Engineering from the same company set). However, Explorium’s API is flexible – it does permit combining company and person attributes in one fetch_prospects call. In cases where the ICP is very specific about the role and company attributes (and the user doesn’t need to separately see the company list), a one-stage contact-first search can be used for efficiency
developers.explorium.ai
. This might be suitable for experienced users or fully automated runs. The system can even offer both modes: e.g. a “Quick Search” that returns contacts immediately, and an “Advanced” mode that lets the user inspect companies first. Data Flow: In both scenarios, the data flow is: user input -> filters -> Explorium search -> IDs -> Explorium enrichment -> final data. The structured filter object (from step 2) is central – it’s used either in fetch_businesses then fetch_prospects, or directly in fetch_prospects. Data returned from Explorium comes with unique identifiers which we use for subsequent calls and deduplication. The platform should maintain mapping of IDs to records internally (e.g. caching which business_id corresponds to which company name, so when contacts come in with just an ID reference, it can attach the company name). Persisting Filter Parameters: It’s crucial to persist the ICP’s filter set in a reusable format. We store the filters as a JSON schema (or equivalent) in a database row for the saved ICP. For example, an ICP record might have columns: id, user_id, profile_name, filter_json, created_at. The filter_json contains the exact payload sent to Explorium (minus the dynamic fields like pagination), e.g.:
{
  "country_code": ["us"],
  "company_size": ["51-200","201-500"],
  "linkedin_category": ["software development"],
  "job_level": ["cxo","vp"],
  "job_department": ["engineering"]
}
Storing this structured data means GTM engineers or other tools can directly reuse it. For instance, a growth engineer could pull this JSON and plug it into a script or a campaign workflow (via Explorium’s API or via our platform’s API) to retrieve updated leads next quarter, ensuring consistency in targeting criteria. We will also persist any parameters used for search, such as the date the search was run, number of results, etc., if we want to track performance. This persistence creates an ICP knowledge base for the team, preventing duplicate effort and enabling iterative refinement over time. Explorium-Supported Filters – Companies: Explorium MCP offers a rich set of filters for narrowing down companies. Below is a list of key company filters and their purpose:
Location – Country/Region/City: Filter by geography at various levels. Use country_code for country (ISO-2 code, e.g. "us" for United States) and region_country_code for state/province (ISO-3166-2, e.g. "us-ca" for California)
developers.explorium.ai
developers.explorium.ai
. For city-level targeting, a combined city_region_country string is used (e.g. "San Francisco, CA, US"), typically obtained via a cascading autocomplete
developers.explorium.ai
. These ensure the search focuses on companies headquartered in desired locations.
Company Size (Employees): Filter by number of employees. Explorium defines size buckets like "1-10", "11-50", "51-200", "201-500", "501-1000", "1001-5000", "5001-10000", "10001+" etc.
developers.explorium.ai
. We can include one or multiple ranges in the filter. In our ICP example, 50–500 employees would translate to ["51-200","201-500"]. Company size is a core ICP attribute as it indicates mid-market vs enterprise.
Annual Revenue: Filter by revenue range. Similar to size, predefined ranges (e.g. "0-500K", "1M-5M", "10M-25M", up to "10B-100B") are used
developers.explorium.ai
. This helps target companies with a certain financial scale. (E.g. mid-size might correlate with $10M–$100M revenue.)
Company Age: Filter by years since establishment. Ranges like "0-3", "4-7", "8-10", "10-20", "20+" years are available
developers.explorium.ai
. This can be useful if, for example, the ICP is interested in startups (young companies) versus well-established firms.
Industry Category: Filter by industry sector. Explorium supports multiple classification systems – e.g. NAICS codes, LinkedIn industry categories, and Google categories. You can use one of these at a time (mixing is not allowed)
developers.explorium.ai
developers.explorium.ai
. For instance:
LinkedIn Category: human-friendly industries like “software development” or “investment banking”
developers.explorium.ai
.
NAICS: numeric codes (2017 NAICS) such as "62" for Health Care & Social Assistance
developers.explorium.ai
.
Google Category: e.g. “Retail” or other business categories
developers.explorium.ai
.
These filters ensure we only get companies in the desired sector. Autocomplete should be used to find the exact terms or codes
developers.explorium.ai
developers.explorium.ai
. In our running example, “B2B SaaS” became LinkedIn category “Software Development” in the filters.
Technology Stack: Filter by technologies the company uses. Two related filters exist:
company_tech_stack_category – broad tech domains the company has (e.g. does the company use any “CRM” tools, any “Cloud Services”, any “Cybersecurity” tools, etc.)
developers.explorium.ai
developers.explorium.ai
.
company_tech_stack_tech – specific software or technologies the company uses (e.g. “AWS”, “Salesforce”, “JavaScript”)
developers.explorium.ai
.
These are powerful for ICPs that involve technographics (for example, targeting companies that use a competitor’s product). In Explorium’s data, if a company’s tech stack includes a given tech, it will match. (In the example user query “companies that use AWS” would utilize company_tech_stack_tech: ["AWS"].)
developers.explorium.ai
developers.explorium.ai
.
Website Keywords: Filter by keywords found on company websites. This allows targeting by specific terms present in the site content, such as “machine learning” or “sustainability”
developers.explorium.ai
. It can be useful for very tailored ICPs, although it may narrow results significantly. Explorium performs an indexed search of company websites for these keywords
developers.explorium.ai
.
Number of Locations: Filter by how many office locations the company has (e.g. "1", "2-5", "6+" branches)
developers.explorium.ai
. This could distinguish single-office companies from those with global footprints.
Company Name: Filter by specific company names. This is essentially a lookup – if an ICP or user wants to ensure certain key accounts are included (or to exclude certain companies), they can provide names
developers.explorium.ai
. This filter is often used via Match Business first to get exact business_ids for those names to avoid ambiguity.
(All the above filters can be combined logically: multiple values in one filter field act as OR (any match) within that field, while different fields act as AND across filters
developers.explorium.ai
developers.explorium.ai
. For example, country_code: ["us"] AND company_size: ["51-200","201-500"] means U.S. companies that are either 51–200 or 201–500 employees
developers.explorium.ai
developers.explorium.ai
.) Explorium-Supported Filters – Individuals (Prospects): When searching for contacts, there are additional filters specific to people, as well as the option to reuse any of the company filters above (prefixed with company_ in the context of prospect search). Key prospect-level filters include:
Job Title: Filter by keywords in job titles. For example job_title: ["Sales Representative"] would match prospects whose title contains those words
developers.explorium.ai
. However, job titles can vary greatly, so this filter does substring matching (all words must appear, in any order) and may miss synonyms
developers.explorium.ai
. Explorium recommends using broader levels/departments when possible, but direct titles are useful for very specific roles (e.g. “Head of Compliance”).
Job Level (Seniority): Filter by seniority category of the role. Examples of values: "CXO" (C-level executives), "vp", "director", "manager", "senior" (for senior contributors), "entry" (entry-level) etc. Using job level ensures you capture all titles at that level. For instance, filtering job_level: ["CXO"] would include CEO, CFO, CTO, etc., and job_level: ["vp"] covers anyone with Vice President in title
developers.explorium.ai
developers.explorium.ai
. In our example, “CTO or Head of Engineering” would map to job_level: ["CXO","director","vp"] combined with department filter (see next) to catch CTO (a C-level) and other heads.
Job Department: Filter by the functional department of the prospect’s role. Values are things like "engineering", "sales", "marketing", "finance", "human resources", etc.
developers.explorium.ai
developers.explorium.ai
. This groups titles by function – e.g. a “Head of Engineering” and “CTO” both fall under engineering/technical department. In practice, combining job_department and job_level is a powerful way to get all decision-makers in a given function. (E.g. department = engineering + level = director/VP/CXO would fetch engineering leaders regardless of exact title wording.)
Years of Experience: Filter by the prospect’s total experience in months. Use total_experience_months with a range – for example, "gte": 60 to get prospects with ≥5 years experience
developers.explorium.ai
. This can refine searches to exclude very junior people or target highly experienced individuals.
Tenure in Current Role: Filter by how long the prospect has been in their current position, via current_role_months. For instance, if an ICP aims at newly appointed execs, one might use "current_role_months": { "lte": 12 } (one year or less in role)
developers.explorium.ai
. Conversely, targeting veterans might use a high "gte" value. This data helps time outreach (new leaders might be more open to new solutions).
Contact Availability: Filters to ensure contact info exists – has_email: true and has_phone: true are boolean filters to return only prospects for whom Explorium can provide a verified email and/or phone number
developers.explorium.ai
developers.explorium.ai
. It’s often wise to set has_email = True so that the resulting prospect list is immediately usable for outreach (no point getting a prospect with no way to contact them). The example ICP for CFOs in NY included both of these filters to guarantee reachable contacts
developers.explorium.ai
.
Specific Person Attributes: In cases where we have a specific individual in mind (not common for broad ICP, but possible for account-based prospecting), Explorium offers match_prospects which can take a name and company or an email to find an exact person’s ID
glama.ai
glama.ai
. That’s more for a lookup use-case than ICP filtering, but it exists. Generally, prospect filtering is meant for persona-based search rather than finding one known person (the latter is handled by direct match by email).
Company-Related Filters in Prospect Search: All the company filters from the earlier list can also be applied within a prospects search to refine by the employer’s attributes. In Explorium’s fetch_prospects, these are typically prefixed with company_ in the JSON. For example: company_country_code, company_size, linkedin_category (implicitly refers to the company’s industry), etc., as shown in the use case examples
developers.explorium.ai
developers.explorium.ai
. In the HR Directors example, the filters included company size, revenue, and NAICS category alongside the job department and level
developers.explorium.ai
. In the CFO example, they used company location, size, revenue, and industry (LinkedIn category) plus the job filters
developers.explorium.ai
. This demonstrates that when fetching prospects, you can be very granular: e.g. “Finance VPs at mid-sized (1001-5000 employee, $500M-$1B revenue) investment banking firms in New York”
developers.explorium.ai
. The system will combine these behind the scenes (AND logic across fields) so only prospects meeting all criteria are returned.
Data Combination and Reuse: After filtering, the data flow proceeds to retrieval. If using the two-stage approach, the list of company business_ids from the first stage is fed into the prospect query as shown earlier
developers.explorium.ai
. If the user saved the filter set, that can be reused directly for new queries (for example, if the ICP is reused next quarter, just rerun the saved filter JSON against the latest data). Explorium’s data is updated in real-time or regularly, so rerunning filters can fetch new companies or prospects that now meet the criteria (e.g. a company grew into the 51–200 range or a new CTO was hired – they would appear on a new run). Finally, the platform should implement error handling for filters: if a user’s ICP description includes a criterion that doesn’t map to any available filter, the system should handle it gracefully. According to Explorium’s guidelines, if a requested filter isn’t supported, the agent should stop or inform the user
glama.ai
. For example, if someone attempted to filter by “company culture = high”, which isn’t a direct filter, the system might drop that criterion or notify the user that this aspect can’t be automatically filtered (though such info could be gathered via enrichment later).
4. Explorium MCP Integration & Setup
To implement the above functionality, we integrate the Explorium AgentSource MCP API into the Next.js platform: API Key and Authentication: Explorium’s API is secured with an API key. After signing up for Explorium, we obtain an API key for our application
developers.explorium.ai
. This key must be stored securely (e.g. in environment variables on the Next.js server). All requests to Explorium’s endpoints include this key in the headers (API_KEY: <key>). The platform might include a setup step where the admin enters their Explorium API key, or the key could be baked in if this is a single-tenant app. Server-Side API Calls: In a Next.js architecture, we use either API Routes or serverless functions to handle calls to Explorium. Whenever the front-end needs data from Explorium (e.g. after the user submits the ICP, or when loading results), it will make a request to our backend (an API route in Next.js). The backend code (Node.js) will then call the appropriate Explorium endpoint (using fetch or a library like Axios). This server-side approach keeps the API key hidden from the client and allows aggregation of results. For example, after the ICP is parsed, our code will do something like:
await axios.post("https://api.explorium.ai/v1/businesses", {
    filters: { ... },
    mode: "full",
    page_size: 100,
    page: 1
}, { headers: { "API_KEY": process.env.EXPLORIUM_KEY } });
This would retrieve businesses matching the filters
developers.explorium.ai
developers.explorium.ai
. We’d then handle pagination if needed (Explorium supports paging through results up to a max size of 10,000 per query)
developers.explorium.ai
developers.explorium.ai
. Integration of Specific Endpoints: We will utilize multiple endpoints from Explorium’s MCP:
Match & Enrich (Onboarding): match-businesses and enrich-businesses-firmographics to get the user’s own company info during onboarding (these return structured data like company name, description, industry codes, size, etc.)
glama.ai
glama.ai
. Similarly, if later we allow users to input a list of named target accounts, we’d use match_businesses to get their IDs for filtering or enrichment.
Fetch Businesses: POST /v1/businesses for retrieving company lists based on filters
developers.explorium.ai
developers.explorium.ai
. We’ll construct the JSON body with the filters from the ICP. The response will include minimal info by default (company names, IDs, perhaps basic firmographics)
developers.explorium.ai
developers.explorium.ai
 which is enough to identify targets. If we set mode: "full", we get complete data records for each company in one go (which could include things like location, size, revenue, etc.)
developers.explorium.ai
developers.explorium.ai
. This is useful for directly displaying company attributes in the UI. The trade-off is payload size, but for moderate result counts it’s fine.
Fetch Prospects: POST /v1/prospects for retrieving people records based on filters
developers.explorium.ai
developers.explorium.ai
. We will use this either with business_id filters (for company-first flow) or with combined filters. The response gives prospect data including prospect_id, name, location, title, etc., but not contact info by default
developers.explorium.ai
developers.explorium.ai
. We see in the example response that personal attributes like skills and interests are returned, but email/phone are not directly included
developers.explorium.ai
developers.explorium.ai
.
Enrich Prospects – Contact Details: POST /v1/prospects/enrich/contact-details for each prospect (or in bulk) to get their email addresses and phone numbers
zapier.com
zapier.com
. Explorium’s data provides verified professional and/or personal emails and sometimes phone numbers for many profiles. We will likely call this in bulk mode (the API allows sending a list of prospect IDs to get contact info for all at once, rather than one-by-one). This enrichment is critical for the platform to deliver actionable output (means to contact the prospects). We might also use other enrichment endpoints like professional profile or social media presence if we want to display additional info about each contact (like LinkedIn URL, etc.)
glama.ai
, but those are secondary. Contact discovery is essentially accomplished by fetch_prospects + enrich_contact_details.
Handling Indian Data & Global Coverage: Explorium’s database is comprehensive globally. It covers 150M+ companies in 150+ countries and over 760M individual professional profiles
explorium.ai
explorium.ai
. This includes Indian companies and contacts. In fact, Explorium advertises fresh data on “150M+ companies and 800M+ people” worldwide
explorium.ai
explorium.ai
, so users targeting regions like India can rely on the platform. We can use filters such as country_code: ["in"] for India or specific region codes for Indian states. The only consideration is that data depth can vary by country – e.g. US data might have more emails than some other regions – but generally India is well represented. If needed, we might allow the user to specify locale-specific parameters (like currency for revenue filters if displaying, etc., though the API itself uses USD for revenue ranges globally). Overall, Explorium provides data for India as part of its global dataset, so an ICP like “Indian SMBs in manufacturing with 10–50 Cr revenue” would be feasible to construct with available filters (with appropriate conversions). Next.js Specifics: Using Next.js, we will take advantage of its SSR and API route capabilities:
The initial ICP parsing (LLM call) can be done server-side on an API route (especially if using an OpenAI API call, to keep that key secure as well). The front-end waits for the API response which contains the structured filters.
The search preview and final search will also hit our API routes which then call Explorium, get data, and respond with the results to the front-end. We will implement loading states on the front-end for a smooth UX.
We should also consider rate limits: Explorium allows up to 200 queries per minute
developers.explorium.ai
developers.explorium.ai
. Our platform should batch requests when possible (for example, sending one bulk request for 1000 prospects instead of 1000 single requests) and perhaps queue searches if a user triggers many in succession to stay within limits. In practice, one ICP search (even two-stage) might involve a handful of API calls (one for companies, one for prospects, one for enrichment), well below rate limits. But if multiple users are using the system, we might build in some limit or monitoring.
Error Handling & Monitoring: Implement robust error handling for API calls. If an Explorium API call fails (network issue, or a bad filter causing a 400), the backend should catch that and return a user-friendly message (e.g. “No data found for these criteria” or “Please refine your filters”). Explorium’s API provides error messages we can pass along or interpret. For instance, if the user inadvertently used two conflicting filters, we should inform them (Explorium notes not to use multiple industry category types together
developers.explorium.ai
). Logging the API responses and any issues will help with debugging and improving the prompts/filters over time. In summary, integrating Explorium MCP in Next.js involves secure server-side calls to fetch and enrich data, with the platform orchestrating those calls in sequence (and feeding outputs from one to the next). Explorium’s unified API is designed for AI-driven workflows, so it returns structured, harmonized data that’s easy to consume in our application
explorium.ai
explorium.ai
. We leverage that by directly populating our UI with the JSON responses (after minimal formatting).
5. Best Practices and Recommendations
Optimized Query Structure: Structure the Explorium queries to be as specific as necessary but not overly narrow. A well-crafted ICP will use multiple filters to hone in on the target, rather than relying on a single attribute. For example, combine industry + size + geography filters to define the market segment, and combine department + seniority for the role, as we’ve done. This multi-filter approach uses AND logic to yield precise results
developers.explorium.ai
. At the same time, avoid including too many ultra-specific filters that could zero out results (a common mistake is filtering on something rare like a very niche tech plus a very strict keyword plus multiple other criteria). If an initial search yields too few results, broaden one of the filters – e.g. include more employee range brackets or use job department instead of an exact title. Explorium’s documentation advises that using a filter with low data coverage may result in a small set, whereas broader filters yield more results
developers.explorium.ai
. So find the balance: use broad filters to cast a wide net on relevant segment, and narrower filters to exclude the clearly irrelevant, but don’t stack too many narrow filters together. One effective strategy is to start broad, then refine. The platform can initially run a broader search (perhaps omitting one of the filters) just to gauge volume, and then tighten it. This aligns with Explorium’s suggested workflow: use a stats or small fetch first to see the scope, then refine filters iteratively
developers.explorium.ai
. We should encourage users to follow this approach via the UI – e.g. show the count in preview and a message like “Too many or too few prospects? Adjust your criteria.” This saves time and API credits by avoiding blindly pulling thousands of records that might not be useful. Leverage Autocomplete & Data Dictionaries: Always use the Explorium autocomplete endpoints for fields like industry categories, technologies, and job titles before finalizing a query
developers.explorium.ai
. This ensures the values exist in Explorium’s taxonomy and avoids API errors. For instance, if the user typed “VP Engineering” and our LLM didn’t exactly match it, calling GET /v1/autocomplete/prospects?field=job_title&query=VP+Engineering could return standardized options like “Vice President of Engineering” which we then use. Similarly, maintain internal dictionaries for common terms (e.g. mapping “CTO” to job_level: CXO + job_department: Engineering). These practices improve match rates and result relevance. Data Modeling for ICPs: Treat ICP definitions as first-class data objects in the system. Each ICP profile can be versioned if edited, and can include performance metrics over time (e.g. how many prospects were generated, how many converted – if that data is fed back – though that’s beyond initial scope). A clear data model might include tables for ICP_Profile, Company (fetched companies with their attributes), and Prospect. When a search is run, you can store the resulting company IDs and prospect IDs linked to that profile (perhaps caching them for quick re-loading of the list). This caching is useful if users frequently revisit the same ICP; it can save API calls by storing recent results and only fetching new changes (Explorium data can update, but frequent re-fetch might be wasteful if done too often). GTM engineers could query these tables or use exported CSVs for analysis. Ensure that the structured filters are stored in a human-editable way too – for instance, in the UI, show the saved ICP in a readable format (so users know what each saved profile contains). Enrichment Strategies: To maximize the value of the prospect data:
Always get verified contact info: As noted, use has_email = True in searches
developers.explorium.ai
 and retrieve contact details via enrichment. A prospect without an email or phone is of little use to an SDR. Explorium’s data provides these, and using those filters saves time by only returning contacts we can reach. Ensure compliance with email use (the platform might integrate with an email validation service or at least note if an email is personal vs business).
Enrich for context where useful: Beyond contact info, consider enriching companies with extra data that could help sales conversations. For example, an SDR might want to know if the target company recently had a funding round or a leadership change. Explorium offers event data (funding, IPOs, exec hires, etc.)
glama.ai
glama.ai
 and company insights (like technographic details, news signals, etc.). While not all of these need to surface in the prospecting list, the architecture can include an “Account Research” view that, when a user clicks a company, it shows data from business_enrichments (like the technographics, funding history, etc. from Explorium) to arm the SDR with talking points. Since the MCP allows pulling these on demand, our system can fetch such data ad-hoc (e.g. via a “Research Company” button using endpoints like enrich_businesses_funding_and_acquisitions or fetch_businesses_events for that company)
glama.ai
glama.ai
. This ties into effective prospecting: having relevant insights can improve outreach quality. We should prioritize globally relevant signals – e.g. for Indian companies, funding news or growth signals might be as relevant as for US companies, so ensure those enrichment endpoints work for all regions (Explorium does have global news and funding data for many countries).
Keep data fresh: Schedule periodic re-enrichment. A best practice is not to rely on static data for too long – people change jobs, companies grow. The platform could allow users to “refresh” an ICP profile’s results. Explorium’s data updates (e.g. if someone’s title changes, a future query might move them out of the filter or bring in a new person). We might implement alerts or triggers (if using webhooks or scheduled jobs) to inform users of significant changes (Explorium has webhook support for real-time events like an employee changing role
glama.ai
glama.ai
). This ensures the sales team always works with current information.
Sales Prospecting Principles: Finally, align the platform’s workflow with proven sales prospecting principles to maximize success:
Focus on ideal fit leads: As the RAIN Group emphasizes, the most important part of prospecting is ensuring the lead is a good fit for your offering
rainsalestraining.com
. Our ICP-driven approach directly serves this – by carefully filtering who is targeted, we help users avoid “spray and pray” and concentrate on high-potential prospects. We should encourage users to spend time refining their ICP (perhaps via tips in the UI or default profiles), because time invested in targeting pays off in higher conversion. The platform’s ability to deeply customize filters supports this quality-over-quantity mindset.
Build a target list systematically: RAIN Group suggests dedicating significant effort to building and researching your target list
rainsalestraining.com
. Our platform streamlines the building part (data retrieval), but users should still research and verify the list. We can integrate features like exporting the list to CRM and then tracking outcomes (were they contacted, did they respond) to close the feedback loop.
Personalize and tailor messages: While not directly in our scope, we can facilitate personalization by providing rich data. For example, if we include each prospect’s LinkedIn URL or recent LinkedIn activity (Explorium can provide social media presence)
zapier.com
, the SDR can reference that in outreach. In essence, we equip the “AI SDR” with data to write better emails (this could even be a future feature – using an LLM to draft an email using the enriched data, but that’s another layer).
Compliance and Privacy: A global prospecting platform must adhere to regulations (GDPR, CAN-SPAM, etc.). We should include best practices like allowing filtering by region to exclude areas if needed, clearly marking if an email is personal (e.g. Gmail) vs professional, and providing means to remove data. Explorium data is external/public, but how it’s used should still follow laws. For Indian contacts, comply with local data protection norms as applicable. This wasn’t explicitly asked, but as a best practice it’s worth keeping in mind in the architecture.
Continuous Improvement: Set up analytics to measure the outcome of searches – e.g. how many prospects were imported to CRM, how many were contacted, etc., and allow users to provide feedback (“These results weren’t relevant”). This can feed into refining the LLM prompt or adding new rules (for instance, if users often remove certain types of companies, maybe add a negative filter). The platform should evolve the ICP profiles as the user learns – essentially acting as a learning system that makes the AI SDR agent more effective over time. Explorium’s breadth of data (company firmographics, technographics, intent signals, etc.) provides a playground for advanced strategies. As an actionable recommendation, periodically review new data signals Explorium introduces (they have 4,000+ data signals
explorium.ai
) and incorporate those that can enhance targeting globally. In summary, by combining a user-friendly natural language interface with Explorium’s powerful data engine, this Next.js AI SDR platform enables sales teams to define their ideal customers in plain English and instantly receive a curated, enriched prospect list. The architecture emphasizes a clear flow (onboard → define ICP → preview → fetch → enrich), robust filter management, and alignment with sales best practices. By following the above strategies – from prompt engineering to data handling and iterative refinement – the platform will not only automate prospecting but do so in a way that consistently yields high-quality leads that match the user’s ICP, ready for effective outreach. Sources: The design and recommendations draw on Explorium’s official documentation for available filters and integration guidelines
developers.explorium.ai
developers.explorium.ai
, as well as best-practice insights from sales training experts (e.g. RAIN Group on focusing on fit
rainsalestraining.com
). These inform an architecture that is data-driven, globally applicable, and tuned for practical sales development needs. By prioritizing relevant filters, data enrichment, and an intuitive user journey, the system supports SDRs in filling their pipeline with the right prospects in a modern, AI-assisted way.
Citations

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Explorium AgentSource MCP AI | Zapier

https://zapier.com/mcp/explorium-agentsource-ca2244

Explorium AgentSource MCP AI | Zapier

https://zapier.com/mcp/explorium-agentsource-ca2244

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Sales Prospecting: Tips, Techniques, and Strategies

https://www.rainsalestraining.com/blog/sales-prospecting

Explorium - B2B Data Foundation for AI Agents & GTM SuccessAI SDR Platform Architecture (Next.js + Explorium MCP)
1. Natural Language ICP Input Processing
User Input Format: Allow B2B users to describe their Ideal Customer Profile in a single, clear natural-language sentence. For example: “I want to target mid-size B2B SaaS companies in the US with 50–500 employees where the CTO or Head of Engineering is the decision maker.” This format explicitly mentions: target company type/industry (“B2B SaaS companies”), geography (“US”), company size (“50–500 employees”), and key decision-maker roles (“CTO or Head of Engineering”). Providing a template or example helps users include all relevant attributes of their ICP in one prompt. Prompt Engineering: On form submission, the system uses an LLM (e.g. OpenAI GPT) to parse the natural-language ICP into structured search parameters. The prompt to the LLM should define the expected output schema (e.g. JSON with fields like industry, company_size, location, job_roles, etc.) and include instructions/rules for format. For instance, instruct the model to use standardized codes or terms – “Output country as ISO 2-letter code (e.g. ‘US’), company size as predefined ranges (‘11-50’, ‘51-200’, etc.), and match job roles to known titles or seniority levels.” This “context engineering” ensures the LLM’s output aligns with Explorium’s API requirements (for example, using "country_code": "us" instead of "country": "United States"). Providing a few examples in the prompt (few-shot learning) can demonstrate how to map phrases like “mid-size” or “SaaS” to structured filters (e.g. company_size: ["51-200","201-500"], linkedin_category: ["software development"] for SaaS software industry
developers.explorium.ai
). The Explorium platform supports natural language queries natively, so this approach aligns with best practices for GTM agent design
explorium.ai
. Contextual Data for Parsing: Optionally, incorporate context from onboarding to improve parsing accuracy. For example, if during onboarding the user provided their own company website, the system could fetch their company’s industry via Explorium and inform the LLM (e.g. “The user’s company is a SaaS HR software provider”) so the LLM can infer that the ICP likely involves similar buyer personas. This additional context can guide prompt responses, but it’s important to explicitly tell the LLM how to use it (e.g. “Given the user’s company industry and the ICP description, output filters...”). Conversion to Filters: After obtaining the LLM’s draft filters, the system should validate and refine them. This includes:
Autocompletion for categories – For fields like industry or job title that require specific values, call Explorium’s Autocomplete API before finalizing filters. For example, if the LLM outputs linkedin_category: "SaaS", use the Autocomplete Businesses endpoint to find the closest valid category (likely “Software Development”)
developers.explorium.ai
. Similarly, for job titles or departments, use Autocomplete Prospects to get standardized values if available. This ensures the filters will be accepted by Explorium MCP (which requires using valid category values obtained via autocomplete)
developers.explorium.ai
developers.explorium.ai
.
Synonym and range handling – Map colloquial terms to filter values. For instance, “mid-size” might be interpreted as employee count 51–500 (covering two Explorium size buckets: “51-200” and “201-500”)
developers.explorium.ai
, and roles like “Head of Engineering” should translate to appropriate seniority and department filters (e.g. job_department: ["engineering"] and job_level: ["director","vp"] to capture engineering leaders). The prompt or a post-processing rule can handle this mapping (possibly by maintaining an internal dictionary of common synonyms to filter values).
By combining prompt-based parsing with programmatic validation, the platform converts a free-text ICP into a structured filter object ready for search. This structured ICP is then stored and used in subsequent steps.
2. User Journey and Flow
The platform guides the user through a multi-step journey from onboarding to viewing a tailored prospect list. Below is the step-by-step flow, with details on UI and backend actions: Step 1: Onboarding – Company Profile Input
User Action: Upon signup, the user is prompted to enter their own company’s website or domain.
System Action: The system uses this domain to fetch the user’s company info via Explorium. For example, it can call Match Business and then Enrich Firmographics to identify the company’s industry, size, and location
glama.ai
glama.ai
. This data helps personalize the experience (e.g. pre-selecting relevant industry filters or providing example ICPs in the same field). If Explorium returns that the user’s company is, say, in the “Software” industry with ~200 employees, the UI might suggest an example ICP targeting similar companies (or complementary industries) to kickstart the process. The onboarding step thus grounds the platform with context about who is using it.
Step 2: Define ICP via NLP
User Action: The user accesses an “Define Your Ideal Customer Profile” screen with a natural-language input box (pre-filled with a hint or the example format). The user types their ICP description in plain language (e.g. the SaaS targeting example above).
System Action: When the user submits the ICP description, the backend invokes the LLM NLP processing pipeline. The LLM (with engineered prompt as described in section 1) parses the description into structured filters. The system then calls Explorium’s Autocomplete endpoints to validate any category or title filters and attaches the corresponding filter codes/values
developers.explorium.ai
developers.explorium.ai
. For instance, if the user wrote “SaaS companies in the US,” the system ensures the filter includes "country_code": "us" and a valid industry classification for “SaaS” (likely the LinkedIn category “software development”
developers.explorium.ai
). The output might be a JSON like:
{
  "country_code": ["us"],
  "company_size": ["51-200","201-500"],
  "linkedin_category": ["software development"],
  "job_title": ["CTO","Head of Engineering"]
}
This structured ICP filter object is saved (e.g. in a database or in-memory state) and will be used for actual searching. Step 3: Search Preview & ICP Confirmation
User Action: The UI now presents a preview of the interpreted ICP and potential search results for confirmation. This preview includes two parts: (a) a filter summary showing how the system interpreted the ICP (e.g. Industry: Software; Location: US; Company Size: 51–500; Roles: CTO or Head of Engineering), and (b) an optional sample of target companies or a count of matches. For example, the platform might display: “Approximately 1,200 companies match your criteria. Examples include TechVision Inc (120 employees, uses AWS) and DataFlow Systems (86 employees) in New York.”
developers.explorium.ai
developers.explorium.ai
. These examples can be obtained by performing a quick Explorium fetch with a small page size to grab a few representative companies. Explorium’s fetch_businesses can return company names and attributes to populate this preview
developers.explorium.ai
. This step lets users verify the ICP filters are on target before pulling a full list.
System Action: To generate the preview, the system calls Explorium’s Business Statistics or a limited Fetch Businesses query. The Business Statistics endpoint can provide aggregate counts (e.g. number of companies in the US SaaS category of that size) for a high-level gauge
developers.explorium.ai
developers.explorium.ai
. Alternatively, a small fetch_businesses (with page_size of say 5) can retrieve a few sample companies
developers.explorium.ai
. The system uses the previously constructed filter object for these calls. The results are displayed in the UI for user review. This is also the stage to allow filter fine-tuning – the user can adjust any filter via UI controls (e.g. sliders for employee range, checkboxes for additional industries, etc.) if the preview doesn’t look right. Such adjustments update the filter object.
Step 4: Save ICP Filters
User Action: Satisfied with the ICP definition, the user saves it (e.g. naming this profile “Mid-size US SaaS Targets”).
System Action: The platform persists the ICP profile to a database. This includes storing the structured filters (likely as a JSON blob or in a structured table) along with meta-data like profile name, creation date, user ID, etc. By saving the exact filter parameters, GTM engineers and sales teams can reuse this ICP in the future without re-entering it. For instance, the saved ICP can be loaded later to run a fresh search or to feed into other tools (like campaign workflows). Storing these parameters ensures consistency in targeting across the team. The filters can also be exported or exposed via an API for integration with other systems. (For example, the JSON could be handed off to a marketing automation tool to continuously update a lead list.)
Step 5: Final Search & Prospect List Generation
User Action: The user triggers the final search (e.g. by clicking “Generate Prospect List”). The UI then shows a loading indicator and eventually displays the resulting list of companies or contacts that match the ICP.
System Action: This step is where Explorium’s MCP (Model Context Protocol) data sources are fully leveraged to fetch and enrich prospects. The platform has two possible approaches here (explained in detail in section 3, Filter Strategy): (a) Two-Stage Search (Companies -> Contacts): The system first queries Explorium for companies that fit the ICP, then finds relevant contacts at those companies. In practice, the backend would call POST /v1/businesses with the filters (possibly with mode: "full" to get detailed company info) to retrieve a list of business IDs and basic firmographics
developers.explorium.ai
developers.explorium.ai
. Next, using those business IDs, it calls POST /v1/prospects with person-level filters (e.g. job titles/levels) plus a filter business_id: [<IDs>] to fetch employees at those target companies
developers.explorium.ai
developers.explorium.ai
. This returns a list of prospect IDs (and possibly names, titles, etc.). Finally, for each prospect ID, the system calls POST /v1/prospects/enrich/contact-details to get contact information (verified email addresses, phone numbers, etc.)
developers.explorium.ai
developers.explorium.ai
. The end result is a list of prospects with their company, title, email/phone, and any other chosen fields, which the UI then displays in a table or CRM-like list. (b) One-Stage Search (Direct Contacts): Alternatively, the system can query contacts in one step by calling fetch_prospects with the combined filters (both company attributes and person attributes) in a single API call. Explorium’s prospect search supports filters like company size, industry, location and job role criteria together
developers.explorium.ai
developers.explorium.ai
. For example, a single request can ask for “prospects with job_level = CXO or VP in Finance department, at companies in US-NY in Investment Banking with 1001-5000 employees”, and Explorium will return matching people directly
developers.explorium.ai
. This yields prospect IDs and some profile info. The system would then call the Contact Details enrichment for those IDs to get emails/phones. While this one-stage approach is efficient, the two-stage approach offers more control (e.g. the ability to review the company list first) and aligns with Explorium’s recommended workflow of fetching business IDs then prospect IDs
developers.explorium.ai
developers.explorium.ai
.
UI Display: The Prospect List page might first show the company list (especially if using the two-stage approach) – e.g. 100 target companies with key firmographics – and allow the user to drill down into each to see contacts. Or it can directly display a unified list of contacts with their company column. At this stage, Explorium MCP has been “triggered” to provide both the targeting (who to contact) and data enrichment for outreach. The user can click on a contact to view detailed info (potentially using other enrichments like social media profile or work history if needed
glama.ai
glama.ai
). The platform should also indicate data freshness or any relevant signals (for example, a contact who “changed role recently” could be highlighted if Explorium’s events data shows that
glama.ai
).
Throughout this journey, Explorium MCP integration is seamless to the user – they experience a natural chat-like or form-based interaction while behind the scenes the system translates their intent into data queries and results. Each step that calls Explorium (onboarding enrichment, preview, final fetch, enrichment) happens via server-side API calls to keep the API key secure and to aggregate results before sending to the front-end.
3. Filter Strategy and Data Flow
Company-First vs. Contact-First Search: We recommend a company-first filtering strategy followed by contact filtering. This means identifying a set of target companies that match the ICP, then finding the right people within those organizations. This approach ensures that prospects truly fit both the company criteria and the buyer persona criteria. It also mirrors Explorium’s best practices: many enrichment tools require first obtaining a business_id for each company and a prospect_id for each person
developers.explorium.ai
developers.explorium.ai
. By fetching companies first, the platform can present those companies for review or further filtering (e.g. “remove Company X from the list”) before pulling contacts. It also allows reuse of the company list for different roles if needed (e.g. one ICP could be used to get CTOs and another to get Heads of Engineering from the same company set). However, Explorium’s API is flexible – it does permit combining company and person attributes in one fetch_prospects call. In cases where the ICP is very specific about the role and company attributes (and the user doesn’t need to separately see the company list), a one-stage contact-first search can be used for efficiency
developers.explorium.ai
. This might be suitable for experienced users or fully automated runs. The system can even offer both modes: e.g. a “Quick Search” that returns contacts immediately, and an “Advanced” mode that lets the user inspect companies first. Data Flow: In both scenarios, the data flow is: user input -> filters -> Explorium search -> IDs -> Explorium enrichment -> final data. The structured filter object (from step 2) is central – it’s used either in fetch_businesses then fetch_prospects, or directly in fetch_prospects. Data returned from Explorium comes with unique identifiers which we use for subsequent calls and deduplication. The platform should maintain mapping of IDs to records internally (e.g. caching which business_id corresponds to which company name, so when contacts come in with just an ID reference, it can attach the company name). Persisting Filter Parameters: It’s crucial to persist the ICP’s filter set in a reusable format. We store the filters as a JSON schema (or equivalent) in a database row for the saved ICP. For example, an ICP record might have columns: id, user_id, profile_name, filter_json, created_at. The filter_json contains the exact payload sent to Explorium (minus the dynamic fields like pagination), e.g.:
{
  "country_code": ["us"],
  "company_size": ["51-200","201-500"],
  "linkedin_category": ["software development"],
  "job_level": ["cxo","vp"],
  "job_department": ["engineering"]
}
Storing this structured data means GTM engineers or other tools can directly reuse it. For instance, a growth engineer could pull this JSON and plug it into a script or a campaign workflow (via Explorium’s API or via our platform’s API) to retrieve updated leads next quarter, ensuring consistency in targeting criteria. We will also persist any parameters used for search, such as the date the search was run, number of results, etc., if we want to track performance. This persistence creates an ICP knowledge base for the team, preventing duplicate effort and enabling iterative refinement over time. Explorium-Supported Filters – Companies: Explorium MCP offers a rich set of filters for narrowing down companies. Below is a list of key company filters and their purpose:
Location – Country/Region/City: Filter by geography at various levels. Use country_code for country (ISO-2 code, e.g. "us" for United States) and region_country_code for state/province (ISO-3166-2, e.g. "us-ca" for California)
developers.explorium.ai
developers.explorium.ai
. For city-level targeting, a combined city_region_country string is used (e.g. "San Francisco, CA, US"), typically obtained via a cascading autocomplete
developers.explorium.ai
. These ensure the search focuses on companies headquartered in desired locations.
Company Size (Employees): Filter by number of employees. Explorium defines size buckets like "1-10", "11-50", "51-200", "201-500", "501-1000", "1001-5000", "5001-10000", "10001+" etc.
developers.explorium.ai
. We can include one or multiple ranges in the filter. In our ICP example, 50–500 employees would translate to ["51-200","201-500"]. Company size is a core ICP attribute as it indicates mid-market vs enterprise.
Annual Revenue: Filter by revenue range. Similar to size, predefined ranges (e.g. "0-500K", "1M-5M", "10M-25M", up to "10B-100B") are used
developers.explorium.ai
. This helps target companies with a certain financial scale. (E.g. mid-size might correlate with $10M–$100M revenue.)
Company Age: Filter by years since establishment. Ranges like "0-3", "4-7", "8-10", "10-20", "20+" years are available
developers.explorium.ai
. This can be useful if, for example, the ICP is interested in startups (young companies) versus well-established firms.
Industry Category: Filter by industry sector. Explorium supports multiple classification systems – e.g. NAICS codes, LinkedIn industry categories, and Google categories. You can use one of these at a time (mixing is not allowed)
developers.explorium.ai
developers.explorium.ai
. For instance:
LinkedIn Category: human-friendly industries like “software development” or “investment banking”
developers.explorium.ai
.
NAICS: numeric codes (2017 NAICS) such as "62" for Health Care & Social Assistance
developers.explorium.ai
.
Google Category: e.g. “Retail” or other business categories
developers.explorium.ai
.
These filters ensure we only get companies in the desired sector. Autocomplete should be used to find the exact terms or codes
developers.explorium.ai
developers.explorium.ai
. In our running example, “B2B SaaS” became LinkedIn category “Software Development” in the filters.
Technology Stack: Filter by technologies the company uses. Two related filters exist:
company_tech_stack_category – broad tech domains the company has (e.g. does the company use any “CRM” tools, any “Cloud Services”, any “Cybersecurity” tools, etc.)
developers.explorium.ai
developers.explorium.ai
.
company_tech_stack_tech – specific software or technologies the company uses (e.g. “AWS”, “Salesforce”, “JavaScript”)
developers.explorium.ai
.
These are powerful for ICPs that involve technographics (for example, targeting companies that use a competitor’s product). In Explorium’s data, if a company’s tech stack includes a given tech, it will match. (In the example user query “companies that use AWS” would utilize company_tech_stack_tech: ["AWS"].)
developers.explorium.ai
developers.explorium.ai
.
Website Keywords: Filter by keywords found on company websites. This allows targeting by specific terms present in the site content, such as “machine learning” or “sustainability”
developers.explorium.ai
. It can be useful for very tailored ICPs, although it may narrow results significantly. Explorium performs an indexed search of company websites for these keywords
developers.explorium.ai
.
Number of Locations: Filter by how many office locations the company has (e.g. "1", "2-5", "6+" branches)
developers.explorium.ai
. This could distinguish single-office companies from those with global footprints.
Company Name: Filter by specific company names. This is essentially a lookup – if an ICP or user wants to ensure certain key accounts are included (or to exclude certain companies), they can provide names
developers.explorium.ai
. This filter is often used via Match Business first to get exact business_ids for those names to avoid ambiguity.
(All the above filters can be combined logically: multiple values in one filter field act as OR (any match) within that field, while different fields act as AND across filters
developers.explorium.ai
developers.explorium.ai
. For example, country_code: ["us"] AND company_size: ["51-200","201-500"] means U.S. companies that are either 51–200 or 201–500 employees
developers.explorium.ai
developers.explorium.ai
.) Explorium-Supported Filters – Individuals (Prospects): When searching for contacts, there are additional filters specific to people, as well as the option to reuse any of the company filters above (prefixed with company_ in the context of prospect search). Key prospect-level filters include:
Job Title: Filter by keywords in job titles. For example job_title: ["Sales Representative"] would match prospects whose title contains those words
developers.explorium.ai
. However, job titles can vary greatly, so this filter does substring matching (all words must appear, in any order) and may miss synonyms
developers.explorium.ai
. Explorium recommends using broader levels/departments when possible, but direct titles are useful for very specific roles (e.g. “Head of Compliance”).
Job Level (Seniority): Filter by seniority category of the role. Examples of values: "CXO" (C-level executives), "vp", "director", "manager", "senior" (for senior contributors), "entry" (entry-level) etc. Using job level ensures you capture all titles at that level. For instance, filtering job_level: ["CXO"] would include CEO, CFO, CTO, etc., and job_level: ["vp"] covers anyone with Vice President in title
developers.explorium.ai
developers.explorium.ai
. In our example, “CTO or Head of Engineering” would map to job_level: ["CXO","director","vp"] combined with department filter (see next) to catch CTO (a C-level) and other heads.
Job Department: Filter by the functional department of the prospect’s role. Values are things like "engineering", "sales", "marketing", "finance", "human resources", etc.
developers.explorium.ai
developers.explorium.ai
. This groups titles by function – e.g. a “Head of Engineering” and “CTO” both fall under engineering/technical department. In practice, combining job_department and job_level is a powerful way to get all decision-makers in a given function. (E.g. department = engineering + level = director/VP/CXO would fetch engineering leaders regardless of exact title wording.)
Years of Experience: Filter by the prospect’s total experience in months. Use total_experience_months with a range – for example, "gte": 60 to get prospects with ≥5 years experience
developers.explorium.ai
. This can refine searches to exclude very junior people or target highly experienced individuals.
Tenure in Current Role: Filter by how long the prospect has been in their current position, via current_role_months. For instance, if an ICP aims at newly appointed execs, one might use "current_role_months": { "lte": 12 } (one year or less in role)
developers.explorium.ai
. Conversely, targeting veterans might use a high "gte" value. This data helps time outreach (new leaders might be more open to new solutions).
Contact Availability: Filters to ensure contact info exists – has_email: true and has_phone: true are boolean filters to return only prospects for whom Explorium can provide a verified email and/or phone number
developers.explorium.ai
developers.explorium.ai
. It’s often wise to set has_email = True so that the resulting prospect list is immediately usable for outreach (no point getting a prospect with no way to contact them). The example ICP for CFOs in NY included both of these filters to guarantee reachable contacts
developers.explorium.ai
.
Specific Person Attributes: In cases where we have a specific individual in mind (not common for broad ICP, but possible for account-based prospecting), Explorium offers match_prospects which can take a name and company or an email to find an exact person’s ID
glama.ai
glama.ai
. That’s more for a lookup use-case than ICP filtering, but it exists. Generally, prospect filtering is meant for persona-based search rather than finding one known person (the latter is handled by direct match by email).
Company-Related Filters in Prospect Search: All the company filters from the earlier list can also be applied within a prospects search to refine by the employer’s attributes. In Explorium’s fetch_prospects, these are typically prefixed with company_ in the JSON. For example: company_country_code, company_size, linkedin_category (implicitly refers to the company’s industry), etc., as shown in the use case examples
developers.explorium.ai
developers.explorium.ai
. In the HR Directors example, the filters included company size, revenue, and NAICS category alongside the job department and level
developers.explorium.ai
. In the CFO example, they used company location, size, revenue, and industry (LinkedIn category) plus the job filters
developers.explorium.ai
. This demonstrates that when fetching prospects, you can be very granular: e.g. “Finance VPs at mid-sized (1001-5000 employee, $500M-$1B revenue) investment banking firms in New York”
developers.explorium.ai
. The system will combine these behind the scenes (AND logic across fields) so only prospects meeting all criteria are returned.
Data Combination and Reuse: After filtering, the data flow proceeds to retrieval. If using the two-stage approach, the list of company business_ids from the first stage is fed into the prospect query as shown earlier
developers.explorium.ai
. If the user saved the filter set, that can be reused directly for new queries (for example, if the ICP is reused next quarter, just rerun the saved filter JSON against the latest data). Explorium’s data is updated in real-time or regularly, so rerunning filters can fetch new companies or prospects that now meet the criteria (e.g. a company grew into the 51–200 range or a new CTO was hired – they would appear on a new run). Finally, the platform should implement error handling for filters: if a user’s ICP description includes a criterion that doesn’t map to any available filter, the system should handle it gracefully. According to Explorium’s guidelines, if a requested filter isn’t supported, the agent should stop or inform the user
glama.ai
. For example, if someone attempted to filter by “company culture = high”, which isn’t a direct filter, the system might drop that criterion or notify the user that this aspect can’t be automatically filtered (though such info could be gathered via enrichment later).
4. Explorium MCP Integration & Setup
To implement the above functionality, we integrate the Explorium AgentSource MCP API into the Next.js platform: API Key and Authentication: Explorium’s API is secured with an API key. After signing up for Explorium, we obtain an API key for our application
developers.explorium.ai
. This key must be stored securely (e.g. in environment variables on the Next.js server). All requests to Explorium’s endpoints include this key in the headers (API_KEY: <key>). The platform might include a setup step where the admin enters their Explorium API key, or the key could be baked in if this is a single-tenant app. Server-Side API Calls: In a Next.js architecture, we use either API Routes or serverless functions to handle calls to Explorium. Whenever the front-end needs data from Explorium (e.g. after the user submits the ICP, or when loading results), it will make a request to our backend (an API route in Next.js). The backend code (Node.js) will then call the appropriate Explorium endpoint (using fetch or a library like Axios). This server-side approach keeps the API key hidden from the client and allows aggregation of results. For example, after the ICP is parsed, our code will do something like:
await axios.post("https://api.explorium.ai/v1/businesses", {
    filters: { ... },
    mode: "full",
    page_size: 100,
    page: 1
}, { headers: { "API_KEY": process.env.EXPLORIUM_KEY } });
This would retrieve businesses matching the filters
developers.explorium.ai
developers.explorium.ai
. We’d then handle pagination if needed (Explorium supports paging through results up to a max size of 10,000 per query)
developers.explorium.ai
developers.explorium.ai
. Integration of Specific Endpoints: We will utilize multiple endpoints from Explorium’s MCP:
Match & Enrich (Onboarding): match-businesses and enrich-businesses-firmographics to get the user’s own company info during onboarding (these return structured data like company name, description, industry codes, size, etc.)
glama.ai
glama.ai
. Similarly, if later we allow users to input a list of named target accounts, we’d use match_businesses to get their IDs for filtering or enrichment.
Fetch Businesses: POST /v1/businesses for retrieving company lists based on filters
developers.explorium.ai
developers.explorium.ai
. We’ll construct the JSON body with the filters from the ICP. The response will include minimal info by default (company names, IDs, perhaps basic firmographics)
developers.explorium.ai
developers.explorium.ai
 which is enough to identify targets. If we set mode: "full", we get complete data records for each company in one go (which could include things like location, size, revenue, etc.)
developers.explorium.ai
developers.explorium.ai
. This is useful for directly displaying company attributes in the UI. The trade-off is payload size, but for moderate result counts it’s fine.
Fetch Prospects: POST /v1/prospects for retrieving people records based on filters
developers.explorium.ai
developers.explorium.ai
. We will use this either with business_id filters (for company-first flow) or with combined filters. The response gives prospect data including prospect_id, name, location, title, etc., but not contact info by default
developers.explorium.ai
developers.explorium.ai
. We see in the example response that personal attributes like skills and interests are returned, but email/phone are not directly included
developers.explorium.ai
developers.explorium.ai
.
Enrich Prospects – Contact Details: POST /v1/prospects/enrich/contact-details for each prospect (or in bulk) to get their email addresses and phone numbers
zapier.com
zapier.com
. Explorium’s data provides verified professional and/or personal emails and sometimes phone numbers for many profiles. We will likely call this in bulk mode (the API allows sending a list of prospect IDs to get contact info for all at once, rather than one-by-one). This enrichment is critical for the platform to deliver actionable output (means to contact the prospects). We might also use other enrichment endpoints like professional profile or social media presence if we want to display additional info about each contact (like LinkedIn URL, etc.)
glama.ai
, but those are secondary. Contact discovery is essentially accomplished by fetch_prospects + enrich_contact_details.
Handling Indian Data & Global Coverage: Explorium’s database is comprehensive globally. It covers 150M+ companies in 150+ countries and over 760M individual professional profiles
explorium.ai
explorium.ai
. This includes Indian companies and contacts. In fact, Explorium advertises fresh data on “150M+ companies and 800M+ people” worldwide
explorium.ai
explorium.ai
, so users targeting regions like India can rely on the platform. We can use filters such as country_code: ["in"] for India or specific region codes for Indian states. The only consideration is that data depth can vary by country – e.g. US data might have more emails than some other regions – but generally India is well represented. If needed, we might allow the user to specify locale-specific parameters (like currency for revenue filters if displaying, etc., though the API itself uses USD for revenue ranges globally). Overall, Explorium provides data for India as part of its global dataset, so an ICP like “Indian SMBs in manufacturing with 10–50 Cr revenue” would be feasible to construct with available filters (with appropriate conversions). Next.js Specifics: Using Next.js, we will take advantage of its SSR and API route capabilities:
The initial ICP parsing (LLM call) can be done server-side on an API route (especially if using an OpenAI API call, to keep that key secure as well). The front-end waits for the API response which contains the structured filters.
The search preview and final search will also hit our API routes which then call Explorium, get data, and respond with the results to the front-end. We will implement loading states on the front-end for a smooth UX.
We should also consider rate limits: Explorium allows up to 200 queries per minute
developers.explorium.ai
developers.explorium.ai
. Our platform should batch requests when possible (for example, sending one bulk request for 1000 prospects instead of 1000 single requests) and perhaps queue searches if a user triggers many in succession to stay within limits. In practice, one ICP search (even two-stage) might involve a handful of API calls (one for companies, one for prospects, one for enrichment), well below rate limits. But if multiple users are using the system, we might build in some limit or monitoring.
Error Handling & Monitoring: Implement robust error handling for API calls. If an Explorium API call fails (network issue, or a bad filter causing a 400), the backend should catch that and return a user-friendly message (e.g. “No data found for these criteria” or “Please refine your filters”). Explorium’s API provides error messages we can pass along or interpret. For instance, if the user inadvertently used two conflicting filters, we should inform them (Explorium notes not to use multiple industry category types together
developers.explorium.ai
). Logging the API responses and any issues will help with debugging and improving the prompts/filters over time. In summary, integrating Explorium MCP in Next.js involves secure server-side calls to fetch and enrich data, with the platform orchestrating those calls in sequence (and feeding outputs from one to the next). Explorium’s unified API is designed for AI-driven workflows, so it returns structured, harmonized data that’s easy to consume in our application
explorium.ai
explorium.ai
. We leverage that by directly populating our UI with the JSON responses (after minimal formatting).
5. Best Practices and Recommendations
Optimized Query Structure: Structure the Explorium queries to be as specific as necessary but not overly narrow. A well-crafted ICP will use multiple filters to hone in on the target, rather than relying on a single attribute. For example, combine industry + size + geography filters to define the market segment, and combine department + seniority for the role, as we’ve done. This multi-filter approach uses AND logic to yield precise results
developers.explorium.ai
. At the same time, avoid including too many ultra-specific filters that could zero out results (a common mistake is filtering on something rare like a very niche tech plus a very strict keyword plus multiple other criteria). If an initial search yields too few results, broaden one of the filters – e.g. include more employee range brackets or use job department instead of an exact title. Explorium’s documentation advises that using a filter with low data coverage may result in a small set, whereas broader filters yield more results
developers.explorium.ai
. So find the balance: use broad filters to cast a wide net on relevant segment, and narrower filters to exclude the clearly irrelevant, but don’t stack too many narrow filters together. One effective strategy is to start broad, then refine. The platform can initially run a broader search (perhaps omitting one of the filters) just to gauge volume, and then tighten it. This aligns with Explorium’s suggested workflow: use a stats or small fetch first to see the scope, then refine filters iteratively
developers.explorium.ai
. We should encourage users to follow this approach via the UI – e.g. show the count in preview and a message like “Too many or too few prospects? Adjust your criteria.” This saves time and API credits by avoiding blindly pulling thousands of records that might not be useful. Leverage Autocomplete & Data Dictionaries: Always use the Explorium autocomplete endpoints for fields like industry categories, technologies, and job titles before finalizing a query
developers.explorium.ai
. This ensures the values exist in Explorium’s taxonomy and avoids API errors. For instance, if the user typed “VP Engineering” and our LLM didn’t exactly match it, calling GET /v1/autocomplete/prospects?field=job_title&query=VP+Engineering could return standardized options like “Vice President of Engineering” which we then use. Similarly, maintain internal dictionaries for common terms (e.g. mapping “CTO” to job_level: CXO + job_department: Engineering). These practices improve match rates and result relevance. Data Modeling for ICPs: Treat ICP definitions as first-class data objects in the system. Each ICP profile can be versioned if edited, and can include performance metrics over time (e.g. how many prospects were generated, how many converted – if that data is fed back – though that’s beyond initial scope). A clear data model might include tables for ICP_Profile, Company (fetched companies with their attributes), and Prospect. When a search is run, you can store the resulting company IDs and prospect IDs linked to that profile (perhaps caching them for quick re-loading of the list). This caching is useful if users frequently revisit the same ICP; it can save API calls by storing recent results and only fetching new changes (Explorium data can update, but frequent re-fetch might be wasteful if done too often). GTM engineers could query these tables or use exported CSVs for analysis. Ensure that the structured filters are stored in a human-editable way too – for instance, in the UI, show the saved ICP in a readable format (so users know what each saved profile contains). Enrichment Strategies: To maximize the value of the prospect data:
Always get verified contact info: As noted, use has_email = True in searches
developers.explorium.ai
 and retrieve contact details via enrichment. A prospect without an email or phone is of little use to an SDR. Explorium’s data provides these, and using those filters saves time by only returning contacts we can reach. Ensure compliance with email use (the platform might integrate with an email validation service or at least note if an email is personal vs business).
Enrich for context where useful: Beyond contact info, consider enriching companies with extra data that could help sales conversations. For example, an SDR might want to know if the target company recently had a funding round or a leadership change. Explorium offers event data (funding, IPOs, exec hires, etc.)
glama.ai
glama.ai
 and company insights (like technographic details, news signals, etc.). While not all of these need to surface in the prospecting list, the architecture can include an “Account Research” view that, when a user clicks a company, it shows data from business_enrichments (like the technographics, funding history, etc. from Explorium) to arm the SDR with talking points. Since the MCP allows pulling these on demand, our system can fetch such data ad-hoc (e.g. via a “Research Company” button using endpoints like enrich_businesses_funding_and_acquisitions or fetch_businesses_events for that company)
glama.ai
glama.ai
. This ties into effective prospecting: having relevant insights can improve outreach quality. We should prioritize globally relevant signals – e.g. for Indian companies, funding news or growth signals might be as relevant as for US companies, so ensure those enrichment endpoints work for all regions (Explorium does have global news and funding data for many countries).
Keep data fresh: Schedule periodic re-enrichment. A best practice is not to rely on static data for too long – people change jobs, companies grow. The platform could allow users to “refresh” an ICP profile’s results. Explorium’s data updates (e.g. if someone’s title changes, a future query might move them out of the filter or bring in a new person). We might implement alerts or triggers (if using webhooks or scheduled jobs) to inform users of significant changes (Explorium has webhook support for real-time events like an employee changing role
glama.ai
glama.ai
). This ensures the sales team always works with current information.
Sales Prospecting Principles: Finally, align the platform’s workflow with proven sales prospecting principles to maximize success:
Focus on ideal fit leads: As the RAIN Group emphasizes, the most important part of prospecting is ensuring the lead is a good fit for your offering
rainsalestraining.com
. Our ICP-driven approach directly serves this – by carefully filtering who is targeted, we help users avoid “spray and pray” and concentrate on high-potential prospects. We should encourage users to spend time refining their ICP (perhaps via tips in the UI or default profiles), because time invested in targeting pays off in higher conversion. The platform’s ability to deeply customize filters supports this quality-over-quantity mindset.
Build a target list systematically: RAIN Group suggests dedicating significant effort to building and researching your target list
rainsalestraining.com
. Our platform streamlines the building part (data retrieval), but users should still research and verify the list. We can integrate features like exporting the list to CRM and then tracking outcomes (were they contacted, did they respond) to close the feedback loop.
Personalize and tailor messages: While not directly in our scope, we can facilitate personalization by providing rich data. For example, if we include each prospect’s LinkedIn URL or recent LinkedIn activity (Explorium can provide social media presence)
zapier.com
, the SDR can reference that in outreach. In essence, we equip the “AI SDR” with data to write better emails (this could even be a future feature – using an LLM to draft an email using the enriched data, but that’s another layer).
Compliance and Privacy: A global prospecting platform must adhere to regulations (GDPR, CAN-SPAM, etc.). We should include best practices like allowing filtering by region to exclude areas if needed, clearly marking if an email is personal (e.g. Gmail) vs professional, and providing means to remove data. Explorium data is external/public, but how it’s used should still follow laws. For Indian contacts, comply with local data protection norms as applicable. This wasn’t explicitly asked, but as a best practice it’s worth keeping in mind in the architecture.
Continuous Improvement: Set up analytics to measure the outcome of searches – e.g. how many prospects were imported to CRM, how many were contacted, etc., and allow users to provide feedback (“These results weren’t relevant”). This can feed into refining the LLM prompt or adding new rules (for instance, if users often remove certain types of companies, maybe add a negative filter). The platform should evolve the ICP profiles as the user learns – essentially acting as a learning system that makes the AI SDR agent more effective over time. Explorium’s breadth of data (company firmographics, technographics, intent signals, etc.) provides a playground for advanced strategies. As an actionable recommendation, periodically review new data signals Explorium introduces (they have 4,000+ data signals
explorium.ai
) and incorporate those that can enhance targeting globally. In summary, by combining a user-friendly natural language interface with Explorium’s powerful data engine, this Next.js AI SDR platform enables sales teams to define their ideal customers in plain English and instantly receive a curated, enriched prospect list. The architecture emphasizes a clear flow (onboard → define ICP → preview → fetch → enrich), robust filter management, and alignment with sales best practices. By following the above strategies – from prompt engineering to data handling and iterative refinement – the platform will not only automate prospecting but do so in a way that consistently yields high-quality leads that match the user’s ICP, ready for effective outreach. Sources: The design and recommendations draw on Explorium’s official documentation for available filters and integration guidelines
developers.explorium.ai
developers.explorium.ai
, as well as best-practice insights from sales training experts (e.g. RAIN Group on focusing on fit
rainsalestraining.com
). These inform an architecture that is data-driven, globally applicable, and tuned for practical sales development needs. By prioritizing relevant filters, data enrichment, and an intuitive user journey, the system supports SDRs in filling their pipeline with the right prospects in a modern, AI-assisted way.
Citations

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

AgentSource MCP

https://developers.explorium.ai/reference/agentsource-mcp

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Explorium AgentSource MCP AI | Zapier

https://zapier.com/mcp/explorium-agentsource-ca2244

Explorium AgentSource MCP AI | Zapier

https://zapier.com/mcp/explorium-agentsource-ca2244

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Explorium - B2B Data Foundation for AI Agents & GTM Success

https://www.explorium.ai/

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Fetch Businesses

https://developers.explorium.ai/reference/fetch_businesses

Fetch Prospects

https://developers.explorium.ai/reference/fetch_prospects

Quick Starts

https://developers.explorium.ai/reference/quick-starts

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Schema | Explorium AgentSource MCP Server | Glama

https://glama.ai/mcp/servers/@explorium-ai/mcp-explorium/schema

Sales Prospecting: Tips, Techniques, and Strategies

https://www.rainsalestraining.com/blog/sales-prospecting

Explorium - B2B Data Foundation for AI Agents & GTM Success